# Profiler API

Psychological profiling service using LLM analysis

## ğŸŒ Production Environment

**URL**: `https://api.hey-watch.me/profiler/`

### Current Status

**âœ… Production Ready** (2025-11-13)

| Item | Value |
|------|-------|
| **LLM Provider** | Groq |
| **Model** | openai/gpt-oss-120b (reasoning model) |
| **Reasoning Effort** | medium |
| **Deploy Date** | 2025-11-13 |
| **Status** | healthy âœ… |

**Health Check**:
```bash
curl https://api.hey-watch.me/profiler/health | jq
```

**Expected Response**:
```json
{
  "status": "healthy",
  "llm_provider": "groq",
  "llm_model": "openai/gpt-oss-120b"
}
```

### Infrastructure

- Microservice architecture
- SSL/HTTPS enabled, CORS configured
- Docker + ECR + systemd
- CI/CD auto-deploy (GitHub Actions)

---

## ğŸ¯ Overview

This API provides psychological profiling by analyzing aggregated audio data using LLM (ChatGPT/Groq).

### Main Features

- **Spot Profiler**: Single recording analysis (`/spot-profiler`) âœ… Production
- **Daily Profiler**: Daily cumulative analysis (`/daily-profiler`) âœ… Production (2025-11-15)
- **Weekly Profiler**: Weekly trend analysis (`/weekly-profiler`) ğŸš§ Coming soon
- **Monthly Profiler**: Monthly long-term analysis (`/monthly-profiler`) ğŸš§ Coming soon
- **Multiple LLM Provider Support**: Easy switching between OpenAI, Groq, etc.
- **Retry Functionality**: Ensures API call stability

---

## ğŸ—ºï¸ Routing Details

| Item | Value | Description |
|------|-------|-------------|
| **ğŸ·ï¸ Service Name** | Profiler API | LLM psychological profiling |
| **ğŸ“¦ Function** | LLM Gateway | ChatGPT/Groq analysis execution |
| | | |
| **ğŸŒ External Access (Nginx)** | | |
| â”” Public Endpoint | `https://api.hey-watch.me/profiler/` | âœ… Unified naming convention |
| â”” Nginx Config File | `/etc/nginx/sites-available/api.hey-watch.me` | |
| â”” proxy_pass Target | `http://localhost:8051/` | Internal forwarding |
| â”” Timeout | 180 seconds | read/connect/send |
| | | |
| **ğŸ”Œ API Internal Endpoints** | | |
| â”” Health Check | `/health` | GET |
| â”” **Spot Profiler** | `/spot-profiler` | POST - Called by audio-worker Lambda |
| â”” **Daily Profiler** | `/daily-profiler` | POST - Called by dashboard-analysis-worker Lambda âœ… |
| â”” **Weekly Profiler** | `/weekly-profiler` | POST - Weekly analysis (ğŸš§ Coming soon) |
| â”” **Monthly Profiler** | `/monthly-profiler` | POST - Monthly analysis (ğŸš§ Coming soon) |
| | | |
| **ğŸ³ Docker/Container** | | |
| â”” Container Name | `profiler-api` | âœ… Unified naming |
| â”” Port (Internal) | 8051 | Inside container |
| â”” Port (Public) | `127.0.0.1:8051:8051` | localhost only |
| â”” Health Check | `/health` | Docker healthcheck |
| | | |
| **â˜ï¸ AWS ECR** | | |
| â”” Repository Name | `watchme-profiler` | âœ… ECR repository |
| â”” Region | ap-southeast-2 (Sydney) | |
| â”” URI | `754724220380.dkr.ecr.ap-southeast-2.amazonaws.com/watchme-profiler:latest` | |
| | | |
| **âš™ï¸ systemd** | | |
| â”” Service Name | `profiler-api.service` | docker-compose management |
| â”” Startup Command | `docker-compose up -d` | |
| â”” Auto Start | enabled | Auto-start on server reboot |
| | | |
| **ğŸ“‚ Directory** | | |
| â”” Source Code | `/Users/kaya.matsumoto/projects/watchme/api/profiler` | Local |
| â”” GitHub Repository | `hey-watchme/api-profiler` | |
| â”” EC2 Location | `/home/ubuntu/profiler-api` | Production execution directory |
| | | |
| **ğŸ”— Caller** | | |
| â”” Lambda Function (Spot) | `watchme-audio-worker` | Spot analysis |
| â”” Call URL (Spot) | âœ… `https://api.hey-watch.me/profiler/spot-profiler` | |
| â”” Lambda Function (Daily) | `watchme-dashboard-analysis-worker` | Daily analysis |
| â”” Call URL (Daily) | âœ… `https://api.hey-watch.me/profiler/daily-profiler` | |
| â”” Environment Variable | `API_BASE_URL=https://api.hey-watch.me` | Inside Lambda |

---

## ğŸ¤– LLM Provider Settings

### Design Concept

This API **supports multiple LLM providers** and can be easily switched.

**Purpose**:
- Quick migration to new models
- Cost optimization (different providers have different pricing)
- Immediate rollback on performance issues
- Multiple models prepared in advance (API keys configured, can switch anytime)

**Features**:
- âœ… No client-side changes required (app/other APIs)
- âœ… 1-line code change â†’ git push to switch
- âœ… Can keep 3-5 providers on standby
- âœ… Model version upgrades follow same procedure

### Currently In Use

- Provider: **Groq**
- Model: **openai/gpt-oss-120b** (reasoning model)
- Reasoning Effort: **medium**

### Supported Providers

| Provider | Example Models | Environment Variable | Status |
|----------|---------------|---------------------|--------|
| **OpenAI** | gpt-4o, gpt-4o-mini, gpt-5-nano, o1-preview | OPENAI_API_KEY | âœ… Configured |
| **Groq** | llama-3.3-70b-versatile, llama-3.1-8b-instant | GROQ_API_KEY | âœ… Configured |
| **Groq via OpenAI** | openai/gpt-oss-120b (reasoning model) | GROQ_API_KEY | âœ… Configured (currently in use) |

### How to Switch Providers

See `llm_providers.py` - change `CURRENT_PROVIDER` and `CURRENT_MODEL` constants.

---

## ğŸ“Œ API Endpoints

### Endpoint Status

| Endpoint | Method | Status | Description |
|----------|---------|--------|-------------|
| `/health` | GET | âœ… Production | Health check |
| `/spot-profiler` | POST | âœ… Production | Spot profiler analysis (single recording) |
| `/daily-profiler` | POST | âœ… Production (2025-11-15) | Daily profiler analysis (1 day) |
| `/weekly-profiler` | POST | ğŸš§ Planned | Weekly profiler analysis (7 days) |
| `/monthly-profiler` | POST | ğŸš§ Planned | Monthly profiler analysis (30 days) |

---

## ğŸ”Œ Endpoint Details

### 1. Health Check âœ…

```bash
curl https://api.hey-watch.me/profiler/health
```

**Response:**
```json
{
  "status": "healthy",
  "timestamp": "2025-11-13T00:00:00.000000",
  "llm_provider": "groq",
  "llm_model": "openai/gpt-oss-120b"
}
```

---

### 2. Spot Profiler âœ…

**v1.0.0 Specification**:
- âœ… `recorded_at` parameter (UTC timestamp)
- âœ… Microservice architecture compliant

```bash
curl -X POST https://api.hey-watch.me/profiler/spot-profiler \
  -H "Content-Type: application/json" \
  -d '{
    "device_id": "9f7d6e27-98c3-4c19-bdfb-f7fda58b9a93",
    "recorded_at": "2025-11-13T12:31:01+00:00"
  }'
```

**Processing Flow**:
1. Fetch prompt from `spot_aggregators.prompt`
2. Execute LLM (Groq/ChatGPT) analysis
3. Save result to `spot_results` table

**Response:**
```json
{
  "status": "success",
  "message": "Spot profiler analysis completed (DB save successful)",
  "device_id": "9f7d6e27-98c3-4c19-bdfb-f7fda58b9a93",
  "recorded_at": "2025-11-13T12:31:01+00:00",
  "analysis_result": {
    "summary": "Description of the situation",
    "vibe_score": -30,
    "behavior": "Working"
  },
  "database_save": true,
  "processed_at": "2025-11-13T12:35:00.000Z",
  "model_used": "groq/openai/gpt-oss-120b"
}
```

---

### 3. Daily Profiler âœ…

**Production** - Since 2025-11-15

```bash
curl -X POST https://api.hey-watch.me/profiler/daily-profiler \
  -H "Content-Type: application/json" \
  -d '{
    "device_id": "d067d407-cf73-4174-a9c1-d91fb60d64d0",
    "local_date": "2025-11-15"
  }'
```

**Data Flow**:
```
daily_aggregators.prompt (from Aggregator API)
    â†“ LLM Analysis
daily_results (1 day = 1 record)
```

**Processing Flow**:
1. Fetch prompt from `daily_aggregators.prompt`
2. Execute LLM (Groq/ChatGPT) analysis
   - Input: 1æ—¥åˆ†ã®spot_resultsã‚’é›†ç´„ã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
   - Output: 1æ—¥ã®ç·åˆçš„ãªå¿ƒç†åˆ†æ
3. Save result to `daily_results` table

**Response:**
```json
{
  "status": "success",
  "message": "Daily profiler analysis completed (DB save successful)",
  "device_id": "d067d407-cf73-4174-a9c1-d91fb60d64d0",
  "local_date": "2025-11-15",
  "analysis_result": {
    "summary": "1æ—¥ã®ç·åˆçš„ãªå¿ƒç†çŠ¶æ…‹ã®èª¬æ˜ï¼ˆæ—¥æœ¬èªï¼‰",
    "vibe_score": 15,
    "behavior": "ä¼šè©±, ä½œæ¥­, ä¼‘æ†©",
    "profile_result": {
      "daily_trend": "1æ—¥ã®å‚¾å‘ã®èª¬æ˜",
      "key_moments": ["é‡è¦ãªç¬é–“1", "é‡è¦ãªç¬é–“2"],
      "emotional_stability": "æ„Ÿæƒ…ã®å®‰å®šæ€§ã®èª¬æ˜"
    }
  },
  "database_save": true,
  "processed_at": "2025-11-15T02:00:00.000Z",
  "model_used": "groq/openai/gpt-oss-120b"
}
```

---

### 4. Weekly Profiler ğŸš§

**Planned** - Phase 4-3

```bash
curl -X POST https://api.hey-watch.me/profiler/weekly-profiler \
  -H "Content-Type: application/json" \
  -d '{
    "device_id": "d067d407-cf73-4174-a9c1-d91fb60d64d0",
    "week_start_date": "2025-11-11"
  }'
```

**Data Flow**:
```
weekly_aggregators.prompt (7 days of daily_results)
    â†“ LLM Analysis
weekly_results (1 week = 1 record)
```

**Processing Flow**:
1. Fetch prompt from `weekly_aggregators.prompt`
2. Execute LLM analysis (7æ—¥åˆ†ã®daily_resultsã‚’åˆ†æ)
3. Save result to `weekly_results` table

---

### 5. Monthly Profiler ğŸš§

**Planned** - Phase 4-4

```bash
curl -X POST https://api.hey-watch.me/profiler/monthly-profiler \
  -H "Content-Type: application/json" \
  -d '{
    "device_id": "d067d407-cf73-4174-a9c1-d91fb60d64d0",
    "year": 2025,
    "month": 11
  }'
```

**Data Flow**:
```
monthly_aggregators.prompt (30 days of daily_results)
    â†“ LLM Analysis
monthly_results (1 month = 1 record)
```

**Processing Flow**:
1. Fetch prompt from `monthly_aggregators.prompt`
2. Execute LLM analysis (30æ—¥åˆ†ã®daily_resultsã‚’åˆ†æ)
3. Save result to `monthly_results` table

---

## ğŸ“Š Database Structure

### spot_aggregators Table (Input Source)

**Prompt fetch source**

This API reads prompts from `spot_aggregators.prompt`.

```sql
CREATE TABLE spot_aggregators (
  device_id TEXT NOT NULL,
  recorded_at TIMESTAMPTZ NOT NULL,  -- UTC
  prompt TEXT NOT NULL,
  context_data JSONB,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  PRIMARY KEY (device_id, recorded_at)
);
```

### spot_results Table (Output Destination)

**Spot profiler analysis results**

```sql
CREATE TABLE spot_results (
  device_id TEXT NOT NULL,
  recorded_at TIMESTAMPTZ NOT NULL,  -- UTC
  vibe_score DOUBLE PRECISION NULL,
  profile_result JSONB NOT NULL,     -- Full analysis result
  summary TEXT,                       -- Dashboard display summary (Japanese)
  behavior TEXT,                      -- Detected behaviors (comma-separated, 3 items)
  created_at TIMESTAMPTZ DEFAULT NOW(),
  llm_model TEXT NULL,
  PRIMARY KEY (device_id, recorded_at)
);
```

**Saved Fields:**
- `vibe_score`: Psychological score (-100 to +100)
- `summary`: Situation summary in Japanese (2-3 sentences, e.g., "æœé£Ÿã®æ™‚é–“ã€‚å®¶æ—ã¨ä¸€ç·’ã«é£Ÿäº‹ã‚’ã—ã¦ã„ã‚‹ã€‚")
- `behavior`: 3 key behaviors, comma-separated (e.g., "ä¼šè©±, é£Ÿäº‹, å®¶æ—å›£ã‚‰ã‚“")
- `profile_result`: Complete analysis result (JSONB)
  - `summary`: Situation summary (same as TEXT column)
  - `behavior`: Detected behaviors (same as TEXT column)
  - `psychological_analysis`: Mood state, description (Japanese), emotion changes (Japanese)
  - `behavioral_analysis`: Detected activities, behavior pattern (Japanese), situation context (Japanese)
  - `acoustic_metrics`: Speech ratio, loudness, voice stability, pitch variability
  - `key_observations`: Notable findings (Japanese array)
- `llm_model`: Model used (e.g., "groq/openai/gpt-oss-120b")
- `created_at`: Auto-generated timestamp

---

## ğŸš€ Deployment

### CI/CD Auto-Deploy

```bash
# Commit & push triggers auto-deploy
git add .
git commit -m "feat: Add new feature"
git push origin main

# GitHub Actions auto-executes (approx. 5 minutes)
# https://github.com/hey-watchme/api-profiler/actions
```

**Auto-execution content:**
1. Build ARM64-compatible Docker image
2. Push to ECR
3. Auto-deploy on EC2
4. Health check

### Service Management Commands (EC2)

```bash
# Check service status
sudo systemctl status profiler-api

# Restart service
sudo systemctl restart profiler-api

# View logs
sudo journalctl -u profiler-api -f
docker logs profiler-api --tail 50
```

---

## ğŸ”§ Environment Variables (.env)

```bash
# LLM API Keys
OPENAI_API_KEY=sk-...
GROQ_API_KEY=gsk-...  # Only when using Groq

# Supabase Settings
SUPABASE_URL=https://qvtlwotzuzbavrzqhyvt.supabase.co
SUPABASE_KEY=your-supabase-key
```

**Note**: Model specification is done in `llm_providers.py` (not environment variables).

---

## ğŸ“¦ Dependencies

```txt
fastapi==0.100.0
uvicorn==0.23.0
pydantic==2.0.2
python-dotenv==1.0.0
openai>=1.0.0
groq>=0.4.0
requests>=2.31.0
python-multipart>=0.0.6
aiohttp>=3.8.0
tenacity>=8.2.0
httpx==0.24.1
gotrue==1.3.0
supabase==2.3.4
```

---

## ğŸ”— Related Services

- **Aggregator API**: `api/aggregator`
- **iOS App**: `ios_watchme_v9`

---

## ğŸ“š API Documentation

- **Swagger UI**: https://api.hey-watch.me/profiler/docs
- **ReDoc**: https://api.hey-watch.me/profiler/redoc

---

## ğŸ“ Changelog

### v1.2.0 (2025-11-15)

**Daily Profiler Production Release** ğŸ‰

**Purpose**: Complete daily cumulative analysis pipeline with local_date support

**New Features:**
1. **Daily Profiler Endpoint** (`/daily-profiler`)
   - Analyzes 1 day of spot recordings
   - Fetches prompt from `daily_aggregators` table
   - Saves results to `daily_results` table
   - Parameter: `local_date` (YYYY-MM-DD format)

2. **local_date Support**
   - Added `local_date` column to `spot_results` table
   - Timezone-aware daily aggregation
   - Consistent date handling across the pipeline

3. **Database Schema Updates**
   - New table: `daily_results`
   - Columns: `device_id`, `local_date`, `vibe_score`, `summary`, `behavior`, `profile_result` (JSONB), `llm_model`

4. **Lambda Integration**
   - Called by `watchme-dashboard-analysis-worker` Lambda function
   - Triggered via SQS queue after Daily Aggregator completes
   - Automatic execution on every spot recording completion

**Data Flow:**
```
Spot Profiler completes
  â†“
SQS: dashboard-summary-queue
  â†“
Lambda: dashboard-summary-worker
  â†“
Aggregator API (/aggregator/daily)
  â†’ daily_aggregators table
  â†“
SQS: dashboard-analysis-queue
  â†“
Lambda: dashboard-analysis-worker
  â†“
Profiler API (/profiler/daily-profiler)
  â†’ daily_results table
```

**Benefits:**
- Complete daily psychological analysis available
- Real-time daily summary updates
- Seamless integration with existing pipeline
- Supports multiple timezones via local_date

**Modified Files:**
- `main.py`: Added `DailyProfilerRequest` and `/daily-profiler` endpoint

**Testing:**
- Production deployment completed
- Lambda integration verified
- Database save tested

---

### v1.1.0 (2025-11-13)

**Japanese Output + Behavior Field** ğŸ‰

**Purpose**: Dashboard display enhancement with Japanese text and behavior tags

**Changes:**
1. **Added `summary` and `behavior` columns** to `spot_results` table
   - `summary` (TEXT): Japanese description for dashboard (2-3 sentences)
   - `behavior` (TEXT): 3 key behaviors, comma-separated (e.g., "ä¼šè©±, é£Ÿäº‹, å®¶æ—å›£ã‚‰ã‚“")

2. **Updated LLM output format**
   - All text fields now in Japanese (summary, mood_description, behavior_pattern, etc.)
   - Added `behavior` field in LLM response
   - Prompt instructs to prioritize "ä¼šè©±" when speech is detected

3. **Database save enhancement**
   - Extract `summary` from LLM response â†’ save to `summary` column
   - Extract `behavior` from LLM response â†’ save to `behavior` column
   - Full analysis still saved in `profile_result` (JSONB)

**Benefits:**
- Direct display in iOS app/Web dashboard (no translation needed)
- User-friendly Japanese descriptions
- Easy behavior pattern visualization

**Testing:**
- Production test completed with real data
- Database save verified (summary and behavior columns populated)
- Example output:
  - summary: "å¹¼ç¨šåœ’ã®å¹´é•·ã•ã‚“ãŒé£Ÿã¹ç‰©ã‚„éŠã³ã«ã¤ã„ã¦è‡ªåˆ†ã§è©±ã—ã¦ã„ã‚‹æ§˜å­ã§ã™ã€‚"
  - behavior: "ä¼šè©±, é£Ÿäº‹, éŠã³"

**Modified Files:**
- `main.py`: Added summary and behavior extraction

---

### v1.0.0 (2025-11-13)

**Initial Release - Production Deployment Completed** âœ…

**Architecture:**
- New Profiler API created (separated from Scorer API)
- Microservice architecture compliant
- UTC-unified time management with `recorded_at`
- CI/CD auto-deploy pipeline (GitHub Actions â†’ ECR â†’ EC2)

**API Changes:**
- Input: `spot_aggregators.prompt` (reads from Supabase)
- Output: `spot_results` (writes to Supabase)
- Request parameter: `recorded_at` (UTC timestamp)
- Endpoint: `/spot-profiler`

**Database Schema:**
- Table: `spot_results`
- Columns: `device_id`, `recorded_at`, `vibe_score`, `profile_result` (JSONB), `llm_model`, `created_at`
- Removed deprecated columns: `local_date`, `local_time`, `behavior_score`, `emotion_score`, `composite_score`
- RLS disabled (internal API only)

**Infrastructure:**
- Container: `profiler-api` (port 8051)
- ECR: `watchme-profiler`
- systemd: `profiler-api.service`
- Nginx: `/profiler/` â†’ `http://localhost:8051/`
- Health check: `/health`

**Testing:**
- Production test completed successfully
- Database save verified
- LLM model: Groq OpenAI GPT-OSS-120B

---

**Developer**: WatchMe
**Version**: 1.1.0
**Status**: âœ… Production Ready
